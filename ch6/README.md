## ch6. 학습 관련 기술들

> 가중치 매개변수의 최적값을 탐색하는 최적화 방법, 가중치 매개변수 초기값, 하이퍼파라미터 설정 방법
>
> 오버피팅의 대응책인 가중치 감소와 드롭아웃등의 정규화 방법, 배치 정규화

### 매개변수 갱신
- 최적화: 매개변수의 최적값을 찾는 문제를 푸는 것
- 확률적 경사 하강법(SGD): 매개변수의 기울기를 구해, 기울어진 방향으로 매개변수 값을 갱신하는 일을 몇번이고 반복해서 점점 최적의 값에 다가가는 것

![image](https://user-images.githubusercontent.com/83503188/163392314-82d71783-a1d6-4fcd-ad9c-e91ee309f3b3.png)

> W는 갱신할 가중치 매개변수, aL/aW는 W에 대한 손실 함수의 기울기, n는 학습률

#### SGD의 단점
- 비등방성 함수에서는 탐색 경로가 비효율적
- SGD의 단점을 개선해주는 방법 3가지: 모멘텀, AdaGrad, Adam


#### 모멘텀

![image](https://user-images.githubusercontent.com/83503188/163392323-839047bb-1cd9-4aba-93d7-61d6619adcdf.png)

> W는 갱신할 가중치 매개변수, aL/aW는 W에 대한 손실 함수의 기울기, n는 학습률, v는 속도

#### AdaGrad
> 학습률
>
> 학습률이 너무 작으면 학습 시간이 너무 길어지고, 반대로 너무 크면 발산하여 학습이 제대로 이뤄지지 않는다.

- 학습률 감소: 학습률을 정하는 효과적인 기술, 학습을 진행하면서 학습률을 점차 줄여가는 방법
- AdaGrads는 개별 매개변수에 적응적으로 학습률을 조정하면서 학습을 진행

![image](https://user-images.githubusercontent.com/83503188/163392329-03098311-094e-41f8-bdd4-8078a08dd666.png)


> h가 새로 등장, 기존 기울기 값을 제곱하여 계속 더 해줌

#### Adam
- 모멘텀과 AdaGrad의 기법을 융합
- 하이퍼파라미터의 ‘편향 보정’이 진행

![image](https://user-images.githubusercontent.com/83503188/163392336-f51c27b9-26d2-4e0d-bd93-d34edc1468c7.png)


### 가중치의 초기값

#### 초기값을 0으로 하면?
- **가중치 감소**기법: 오버피팅을 억제해 범용 성능을 높이는 테크닉, 가중치 매개변수의 값이 작아지도록 학습하는 방법
- 초기값을 모두 0으로 해서는 안된다. 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문
- Xavier 초기값을 권장


#### ReLU를 사용할 때의 가중치 초기값
- ReLU를 이용할 때는 ReLU에 특화된 초기값인 **He 초기값**을 이용하라고 권장
- He 초기값은 앞 계층의 노드가 n개일 때, 표준편차가 sqrt(2/n)인 정규분포를 사용 => xavier 초기값은 sqrt(1/N)


### 배치 정규화
- 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것


1. 학습을 빨리 진행할 수 있다(학습 속도 개선)
2. 초기값에 크게 의존하지 않는다
3. 오버피팅을 억제한다(드롭아웃 등의 필요성 감소)

![image](https://user-images.githubusercontent.com/83503188/163392345-78d4b73e-9707-464d-9a14-40e5284e7f3c.png)


- 데이터 분포를 정규화하는 `배치 정규화 계층`을 신경망에 삽입
- 배치 정규화는 학습 시 미니배치를 단위로 정규화, 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화


### 바른 학습을 위해
- 오버피팅: 신경망이 훈련 데이터에만 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태


#### 오버피팅
- 오버피팅이 주로 일어나는 두 경우

1. 매개변수가 많고 표현력이 높은 모델
2. 훈련 데이터가 적음

#### 가중치 감소

- 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하여 오버피팅을 억제하는 방법 

#### 드롭아웃
- 뉴런을 임의로 삭제하면서 학습하는 방법, 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제
- 모델을 적은 데이터로 학습시켜 범용 능력을 키우는 방법

![image](https://user-images.githubusercontent.com/83503188/163392355-5d0356d0-41e7-4426-84a4-3df45b01a794.png)



### 적절한 하이퍼파라미터 값 찾기

#### 검증 데이터
- 훈련 데이터로는 학습, 시험 데이터로는 범용 성능을 평가
- 하이퍼파라미터가 대상일 때는 시험 데이터를 사용해서는 안되는 이유는 시험 데이터를 사용하여 하이퍼파라미터를 조정하면 하이퍼파라미터 값이 시험 데이터에 오버피팅 되기 때문
- 하이퍼파라미터를 조정할 때는 하이퍼파라미터 전용 확인 데이터인 **검증 데이터**를 사용

> 훈련 데이터: 매개변수(가중치와 편향)의 학습에 이용
>
> 검증 데이터: 하이퍼파라미터의 성능을 평가하는데 이용
>
> 시험 데이터: 범용 성능을 

### 정리
> 이번 장에서 배운 내용
- 매개변수 갱신 방법에는 확률적 경사 하강법(SGD), 모멘텀, AdaGrad, Adam 등이 있다.
- 가중치 초기값을 정하는 방법은 올바른 학습을 하는 데 매우 중요하다.
- 가중치의 초기값으로는 ‘Xavier 초기값’과 ‘He 초기값’이 효과적이다.
- 배치 정규화를 이용하면 학습을 빠르게 진행할 수 있으며, 초기값에 영향을 덜 받게 된다.
- 오버피팅을 억제하는 정규화 기술로는 가중치 감소와 드롭아웃이 있다.
- 하이퍼파라미터 값 탐색은 최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적이다
